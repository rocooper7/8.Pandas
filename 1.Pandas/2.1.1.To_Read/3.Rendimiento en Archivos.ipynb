{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_pandas = 'C:\\\\Jupyter\\\\5.Numpy_Pandas\\\\1.Pandas\\\\6.To_Read'\n",
    "#https://colab.research.google.com/drive/1Dv0VUSCSoVwOLiBP_yWBm0YWwheIAtaS#scrollTo=Q-b5aCX4UshZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from uuid import uuid4\n",
    "import os\n",
    "import time\n",
    "import tracemalloc\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n_rows, num_count, cat_count, max_nan=0.1, max_cat_size=100):\n",
    "    \"\"\"Randomly generate datasets with numerical and categorical features.\n",
    "    \n",
    "    The numerical features are taken from the normal distribution X ~ N(0, 1).\n",
    "    The categorical features are generated as random uuid4 strings with \n",
    "    cardinality C where 2 <= C <= max_cat_size.\n",
    "    \n",
    "    Also, a max_nan proportion of both numerical and categorical features is replaces\n",
    "    with NaN values.\n",
    "    \"\"\"\n",
    "    dataset, types = {}, {}\n",
    "    \n",
    "    def generate_categories():\n",
    "        \n",
    "        category_size = np.random.randint(2, max_cat_size)\n",
    "        return [str(uuid4()) for _ in range(category_size)]\n",
    "    \n",
    "    for col in range(num_count):\n",
    "        name = f'n{col}'\n",
    "        values = np.random.normal(0, 1, n_rows)\n",
    "        nan_cnt = np.random.randint(1, int(max_nan*n_rows))\n",
    "        index = np.random.choice(n_rows, nan_cnt, replace=False)\n",
    "        values[index] = np.nan\n",
    "        dataset[name] = values\n",
    "        types[name] = 'float32'\n",
    "        \n",
    "    for col in range(cat_count):\n",
    "        name = f'c{col}'\n",
    "        cats = generate_categories()\n",
    "        values = np.array(np.random.choice(cats, n_rows, replace=True), dtype=object)\n",
    "        nan_cnt = np.random.randint(1, int(max_nan*n_rows))\n",
    "        index = np.random.choice(n_rows, nan_cnt, replace=False)\n",
    "        values[index] = np.nan\n",
    "        dataset[name] = values\n",
    "        types[name] = 'object'\n",
    "    \n",
    "    return pd.DataFrame(dataset), types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_of(filename, unit=1024**2):\n",
    "    return round(os.stat(filename).st_size / unit, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_load(df, fmt):\n",
    "    save = getattr(df, f'to_{fmt}')\n",
    "    load = getattr(pd, f'read_{fmt}')\n",
    "    return save, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(list_of_formats,\n",
    "              data_size=1000000,\n",
    "              n_num=15,\n",
    "              n_cat=15,\n",
    "              n_rounds=20,\n",
    "              as_category=False):\n",
    "    \"\"\"Runs dataset saving/loading benchamrk using formts from the list_of_formats.\n",
    "    \n",
    "    Each round a new random dataset is generated with data_size observations. \n",
    "    The measurements for each of the rounds are concatenated together and returned\n",
    "    as a single data frame.\n",
    "    \n",
    "    Parameters:\n",
    "        list_of_formats: A list of tuples in the format (<format_name>, [<params_dict>]). \n",
    "            The <format_name> should be one of the pandas supported formats.\n",
    "        data_size: A number of samples in the generated dataset.\n",
    "        n_num: A number of numerical columns in the generated dataset.\n",
    "        n_cat: A number of categorical columns in the generated dataset.\n",
    "        n_rounds: A number of randomly generated datasets to test the formats.\n",
    "        as_category: If True, then categorical columns will be converted into \n",
    "            pandas.Category type before saving.\n",
    "            \n",
    "    \"\"\"\n",
    "    runs = []\n",
    "    n = 1\n",
    "    cnt = 0\n",
    "\n",
    "    for j in range(n_rounds):\n",
    "        print('Benchmarking round # {}'.format(j))\n",
    "        #print('generating dataset...')\n",
    "        dataset, _ = generate_dataset(data_size, n_num, n_cat)\n",
    "        \n",
    "        if as_category:\n",
    "            #print('converting categorical columns into pandas.Category')\n",
    "            cat_cols = dataset.select_dtypes(include=object).columns\n",
    "            dataset[cat_cols] = dataset[cat_cols].fillna('none').astype('category')\n",
    "        \n",
    "        for case in list_of_formats:\n",
    "              fmt, params = case if len(case) == 2 else (case[0], {})\n",
    "            \n",
    "              print('testing format: {}'.format(fmt))\n",
    "              filename = 'random.{}'.format(fmt)\n",
    "              save, load = get_save_load(dataset, fmt)\n",
    "              results = {}\n",
    "              \n",
    "              results['format'] = fmt\n",
    "              results['filename'] = filename\n",
    "\n",
    "              tracemalloc.start()\n",
    "              start = time.time()\n",
    "              for i in range(n):\n",
    "                  save(dir_pandas + filename, **params)\n",
    "              end = (time.time()- start) / n\n",
    "              current, peak = tracemalloc.get_traced_memory()\n",
    "              tracemalloc.stop()\n",
    "\n",
    "              results['size_mb'] = size_of(dir_pandas + filename)\n",
    "              results['save_ram_mb'] = current / 10**6\n",
    "              results['save_ram_peak_mb'] = peak / 10**6\n",
    "              results['save_time'] = end\n",
    "              \n",
    "              tracemalloc.start()\n",
    "              start = time.time()\n",
    "              for i in range(n):\n",
    "                  _ = load(filename)\n",
    "              end = (time.time()- start) / n\n",
    "              current, peak = tracemalloc.get_traced_memory()\n",
    "              tracemalloc.stop()\n",
    "\n",
    "              results['load_ram_mb'] = current / 10**6\n",
    "              results['load_ram_peak_mb'] = peak / 10**6\n",
    "              results['load_time'] = end\n",
    "\n",
    "              results['run_no'] = j\n",
    "\n",
    "              cnt += 1\n",
    "              run = pd.DataFrame(results,[cnt])\n",
    "              runs.append(run)\n",
    "            \n",
    "    benchmark = pd.concat(runs, axis=0)\n",
    "    benchmark.reset_index(inplace=True, drop=True)\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "formats = [\n",
    "    ('json',),\n",
    "    ('csv', {'index': None}),\n",
    "    ('hdf', {'key': 'data', 'format': 'table'}),\n",
    "    ('pickle',),\n",
    "    #('msgpack',),\n",
    "    #('feather',),\n",
    "    #('parquet', {'engine': 'pyarrow'})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Benchmarking round # 0\ntesting format: json\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-a47af8d37ba7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[0mn_cat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               \u001b[0mn_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m               as_category=False)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-57e961089fd1>\u001b[0m in \u001b[0;36mbenchmark\u001b[1;34m(list_of_formats, data_size, n_num, n_cat, n_rounds, as_category)\u001b[0m\n\u001b[0;32m     63\u001b[0m               \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m               \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m               \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m               \u001b[0mcurrent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeak\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtracemalloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_traced_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"frame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"series\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m             self.obj = DataFrame(\n\u001b[1;32m-> 1089\u001b[1;33m                 \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1090\u001b[0m             )\n\u001b[0;32m   1091\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "results_io = benchmark(formats,\n",
    "              data_size=100000,\n",
    "              n_num=15,\n",
    "              n_cat=15,\n",
    "              n_rounds=1,\n",
    "              as_category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = results_io.groupby('format').mean().reset_index().drop(columns=['run_no'])\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_speed = avg[~avg['format'].isin([])][['format', 'save_time', 'load_time']].melt(id_vars='format')\n",
    "ax = sns.barplot(x='format', y='value', hue='variable', data=io_speed, palette=\"magma\")\n",
    "_ = ax.set_xlabel('File Format')\n",
    "_ = ax.set_ylabel('Seconds')\n",
    "_ = ax.set_title('Time to Save/Load a Data Frame')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_size = avg[~avg['format'].isin([])][['format', 'save_ram_peak_mb', 'load_ram_peak_mb']].melt(id_vars='format')\n",
    "ax = sns.barplot(x='format', y='value', hue='variable', data=mem_size, palette=\"magma\")\n",
    "_ = ax.set_xlabel('File Format')\n",
    "_ = ax.set_ylabel('Memory, Mb')\n",
    "ax.set_title('Memory Peaks Consumption Growth When Saving/Loading')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x='format', y='size_mb', data=avg, palette=\"magma\")\n",
    "_ = ax.set_ylabel('Memory, Mb')\n",
    "_ = ax.set_xlabel('File Format')\n",
    "_ = ax.set_title('Serialized File Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_io_cat = benchmark(formats,\n",
    "              data_size=100000,\n",
    "              n_num=15,\n",
    "              n_cat=15,\n",
    "              n_rounds=1,\n",
    "              as_category=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = results_io_cat.groupby('format').mean().reset_index().drop(columns=['run_no'])\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_speed = avg[~avg['format'].isin(['json','csv'])][['format', 'save_time', 'load_time']].melt(id_vars='format')\n",
    "ax = sns.barplot(x='format', y='value', hue='variable', data=io_speed, palette=\"magma\")\n",
    "_ = ax.set_xlabel('File Format')\n",
    "_ = ax.set_ylabel('Seconds')\n",
    "_ = ax.set_title('Time to Save/Load a Data Frame\\n(categories)')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_size = avg[~avg['format'].isin(['json','csv'])][['format', 'save_ram_peak_mb', 'load_ram_peak_mb']].melt(id_vars='format')\n",
    "ax = sns.barplot(x='format', y='value', hue='variable', data=mem_size, palette=\"magma\")\n",
    "_ = ax.set_xlabel('File Format')\n",
    "_ = ax.set_ylabel('Memory, Mb')\n",
    "ax.set_title('Memory Consumption Growth When Saving/Loading\\n(categories)')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x='format', y='size_mb', data=avg, palette=\"magma\")\n",
    "_ = ax.set_ylabel('Memory, Mb')\n",
    "_ = ax.set_xlabel('File Format')\n",
    "_ = ax.set_title('Serialized File Size\\n(categories)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curso: Análisis de datos con Pandas\n",
    "Clase: I/O Tools\n",
    "Nivel: Intermedio\n",
    "Keywords: Load - Save - Time - Size - DataFrame - Input - Output - Tools\n",
    "\n",
    "Abstract:\n",
    "En esta clase te enseñaremos sobre diversos formatos de almacenamiento de datos y cómo elegir el formato eficiente que se adapte a tus necesidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "CSV y formatos String : Son simples, requieren alto costo computacional y algo lentos.\n",
    "\n",
    "HDF : Gran soporte, adecuado para grandes cantidades de datos, rápido a costo de alto costo computacional.\n",
    "\n",
    "Parquet : Puede igualar a hdf e inclusive trabajar por chunks y en paralelo.\n",
    "\n",
    "Pickle : Es práctico pero lento con grandes cantidades de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('Anaconda': conda)",
   "language": "python",
   "name": "python37464bitanacondaconda74954a3f106b47d99d44e5fb8ca66932"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}